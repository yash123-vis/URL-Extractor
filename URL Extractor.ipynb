{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def google_search(query, num_results=1000000):\n",
        "    search_url = \"https://www.google.com/search?q={}&num={}\".format(query, num_results)\n",
        "    response = requests.get(search_url)\n",
        "    return response.text\n",
        "\n",
        "def extract_urls(html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    links = soup.find_all('a')\n",
        "    urls = []\n",
        "    for link in links:\n",
        "        href = link.get('href')\n",
        "        if href and \"arcgis/rest/services\" in href:\n",
        "            urls.append(href.split('&')[0].replace(\"/url?q=\", \"\"))\n",
        "    return urls\n",
        "\n",
        "def is_valid_url(url):\n",
        "    return url.startswith('http') and 'arcgis/rest/services' in url\n",
        "\n",
        "def save_to_csv(urls, filename=\"urls.csv\"):\n",
        "    df = pd.DataFrame(urls, columns=[\"URL\"])\n",
        "    df['URL'] = df['URL'].apply(lambda x: x.split('&')[0].replace(\"/url?q=\", \"\"))\n",
        "    df = df[df['URL'].apply(is_valid_url)]\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"File '{filename}' has been saved successfully.\")\n",
        "\n",
        "# Perform search and extract URLs\n",
        "html = google_search(\"arcgis/rest/services\")\n",
        "urls = extract_urls(html)\n",
        "\n",
        "# Save to CSV\n",
        "save_to_csv(urls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnTkJmvZv9UX",
        "outputId": "fda3c841-d7e5-4afe-d9a3-8ded95bd11cd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'urls.csv' has been saved successfully.\n"
          ]
        }
      ]
    }
  ]
}